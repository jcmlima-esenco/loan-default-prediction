{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como trabalho final do curso.\n",
    "Desafio. Prever a inadimplência de uma operação de emprestimo.\n",
    "\n",
    "Este desafio foi pública inicialmente em 2013.\n",
    "\n",
    "O desafio inicial pode ser visto em \n",
    "https://www.kaggle.com/c/loan-default-prediction/data\n",
    "    \n",
    "\n",
    "Sobre o desafio\n",
    "\n",
    "Essa competição solicita que você determine se um empréstimo será inadimplente, bem como a perda incorrida se não ocorrer. \n",
    "Diferentemente das abordagens tradicionais baseadas em finanças para esse problema, onde se distingue entre contrapartes boas ou ruins de uma maneira binária, procuramos antecipar e incorporar o padrão e a gravidade das perdas resultantes. Ao fazer isso, estamos construindo uma ponte entre o sistema bancário tradicional, em que buscamos reduzir o consumo de capital econômico, para uma perspectiva de gerenciamento de ativos, na qual otimizamos o risco para o investidor financeiro.\n",
    "\n",
    "Sobre o dataset\n",
    "\n",
    "Esses dados correspondem a um conjunto de transações financeiras associadas a indivíduos. \n",
    "Os dados foram padronizados, descendentes e anonimizados. \n",
    "Você recebe mais de duzentas mil observações e quase 800 recursos. \n",
    "Cada observação é independente da anterior.\n",
    "Para cada observação, foi registrado se um padrão foi acionado.\n",
    "Em caso de inadimplência, a perda foi medida. \n",
    "Essa quantidade está entre 0 e 100. \n",
    "Foi normalizada, considerando que o ideal de cada transação no início é 100. \n",
    "Por exemplo, uma perda de 60 significa que apenas 40 são reembolsados. \n",
    "Se o empréstimo não for inadimplente, a perda será 0. \n",
    "Você deverá prever as perdas para cada observação no conjunto de testes.\n",
    "Os valores dos recursos ausentes foram mantidos como estão, para que as equipes concorrentes possam realmente usar o máximo de dados disponíveis, implementando uma estratégia para preencher as lacunas, se desejado. \n",
    "Observe que algumas variáveis podem ser categóricas (por exemplo, f776 e f777).\n",
    "O patrocinador da competição trabalhou para remover a dimensionalidade do tempo dos dados. No entanto, as observações ainda estão listadas na ordem do antigo para o novo no conjunto de treinamento. \n",
    "No conjunto de teste, eles estão em ordem aleatória.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "sns.set(font_scale = 2)\n",
    "%matplotlib inline\n",
    "mpl.pyplot.rcParams['font.size'] = 24\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jcmlima/opt/anaconda3/envs/bernardo/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (135,204,274,417) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>...</th>\n",
       "      <th>f750</th>\n",
       "      <th>f751</th>\n",
       "      <th>f752</th>\n",
       "      <th>f753</th>\n",
       "      <th>f754</th>\n",
       "      <th>f755</th>\n",
       "      <th>f756</th>\n",
       "      <th>f757</th>\n",
       "      <th>f758</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "      <th>f769</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.686842</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>13699</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>126.75</td>\n",
       "      <td>126.03</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>612922</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>1.097851e+09</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>998046.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3451</td>\n",
       "      <td>0.030594</td>\n",
       "      <td>1.7418</td>\n",
       "      <td>1.5271</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.028362</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>2.5162</td>\n",
       "      <td>2.0037</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>4.4352</td>\n",
       "      <td>4.2676</td>\n",
       "      <td>-0.1524</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.6280</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>5</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>84645</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>123.52</td>\n",
       "      <td>121.35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>245815</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>8.449459e+08</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>754416.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5666</td>\n",
       "      <td>0.120442</td>\n",
       "      <td>1.1963</td>\n",
       "      <td>1.0322</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.2389</td>\n",
       "      <td>0.130160</td>\n",
       "      <td>2.7659</td>\n",
       "      <td>1.9523</td>\n",
       "      <td>1.4059</td>\n",
       "      <td>0.115277</td>\n",
       "      <td>3.2763</td>\n",
       "      <td>2.7962</td>\n",
       "      <td>-0.3097</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.2300</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>-0.6787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>83607</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>126.49</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>1385872</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>1.308478e+09</td>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>1037651.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.43</td>\n",
       "      <td>94.37</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5627</td>\n",
       "      <td>0.226336</td>\n",
       "      <td>3.3277</td>\n",
       "      <td>3.4166</td>\n",
       "      <td>1.8321</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.103307</td>\n",
       "      <td>6.8623</td>\n",
       "      <td>5.2963</td>\n",
       "      <td>4.1282</td>\n",
       "      <td>0.219729</td>\n",
       "      <td>8.1381</td>\n",
       "      <td>7.3269</td>\n",
       "      <td>-0.1909</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-5.18</td>\n",
       "      <td>13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>82642</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>132.94</td>\n",
       "      <td>133.58</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>704687</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.5923</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.8158</td>\n",
       "      <td>1.472752e+09</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "      <td>1115721.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>114.63</td>\n",
       "      <td>102.92</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6899</td>\n",
       "      <td>0.054630</td>\n",
       "      <td>1.3748</td>\n",
       "      <td>1.3421</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>2.5571</td>\n",
       "      <td>2.0593</td>\n",
       "      <td>1.6653</td>\n",
       "      <td>0.056470</td>\n",
       "      <td>3.2516</td>\n",
       "      <td>3.0631</td>\n",
       "      <td>-0.1770</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>-0.5100</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>4</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900</td>\n",
       "      <td>4</td>\n",
       "      <td>79124</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>112.77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>51985</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>1.442916e+09</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>536400.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9179</td>\n",
       "      <td>0.085330</td>\n",
       "      <td>7.2175</td>\n",
       "      <td>6.2262</td>\n",
       "      <td>3.1446</td>\n",
       "      <td>1.6149</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>15.9080</td>\n",
       "      <td>12.5688</td>\n",
       "      <td>9.9844</td>\n",
       "      <td>0.067540</td>\n",
       "      <td>17.5561</td>\n",
       "      <td>15.6079</td>\n",
       "      <td>-0.4444</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.4277</td>\n",
       "      <td>-11.12</td>\n",
       "      <td>26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9     f10  \\\n",
       "0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  126.03   \n",
       "1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  121.35   \n",
       "2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  126.49   \n",
       "3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  133.58   \n",
       "4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  112.77   \n",
       "\n",
       "   f13     f14     f15      f16     f17     f18     f19     f20     f21  \\\n",
       "0    7  0.7607  0.7542   612922  0.7236  0.7236  0.5171  0.7236  0.8476   \n",
       "1    7  0.6555  0.6555   245815  0.6341  0.6341  0.3909  0.6667  0.6903   \n",
       "2    7  0.7542  0.7542  1385872  0.7542  0.7542  0.5508  0.7542  0.8091   \n",
       "3    7  0.8017  0.7881   704687  0.7881  0.7881  0.5923  0.7881  0.8230   \n",
       "4    6  0.5263  0.5263    51985  0.5263  0.5263  0.3044  0.5405  0.5556   \n",
       "\n",
       "      f22           f23  f24  f25        f26   f27   f28     f29     f30  \\\n",
       "0  0.7876  1.097851e+09   89   66   998046.0  89.0  89.0   89.00   89.00   \n",
       "1  0.6903  8.449459e+08   78   50   754416.0  78.0  78.0   78.00   78.00   \n",
       "2  0.7807  1.308478e+09   89   54  1037651.0  89.0  89.0  100.43   94.37   \n",
       "3  0.8158  1.472752e+09   93   55  1115721.0  93.0  93.0  114.63  102.92   \n",
       "4  0.5455  1.442916e+09   60   21   536400.0  60.0  60.0   60.00   60.00   \n",
       "\n",
       "    f31  ...     f750      f751    f752    f753    f754    f755      f756  \\\n",
       "0  89.0  ...   2.3451  0.030594  1.7418  1.5271  0.8474  0.4715  0.028362   \n",
       "1  78.0  ...   1.5666  0.120442  1.1963  1.0322  0.4843  0.2389  0.130160   \n",
       "2  89.0  ...   4.5627  0.226336  3.3277  3.4166  1.8321  0.9979  0.103307   \n",
       "3  93.0  ...   1.6899  0.054630  1.3748  1.3421  0.7982  0.4810  0.081205   \n",
       "4  60.0  ...  11.9179  0.085330  7.2175  6.2262  3.1446  1.6149  0.074286   \n",
       "\n",
       "      f757     f758    f759      f760     f761     f762    f763  f764  f765  \\\n",
       "0   3.1611   2.5162  2.0037  0.019636   4.4352   4.2676 -0.1524     1 -0.40   \n",
       "1   2.7659   1.9523  1.4059  0.115277   3.2763   2.7962 -0.3097     1 -0.17   \n",
       "2   6.8623   5.2963  4.1282  0.219729   8.1381   7.3269 -0.1909     1 -0.58   \n",
       "3   2.5571   2.0593  1.6653  0.056470   3.2516   3.0631 -0.1770     1 -0.75   \n",
       "4  15.9080  12.5688  9.9844  0.067540  17.5561  15.6079 -0.4444     1 -0.18   \n",
       "\n",
       "    f766   f767    f768   f769  f770  f771  f772  f773    f774    f775  f776  \\\n",
       "0 -0.560 -0.440 -0.6280  -3.14     5  2.14 -1.54  1.18  0.1833  0.7873     1   \n",
       "1 -0.275 -0.203 -0.2300  -1.38     6  0.54 -0.24  0.13  0.1926 -0.6787     1   \n",
       "2 -0.540 -0.572 -0.3985  -5.18    13  2.89 -1.73  1.04  0.2521  0.7258     1   \n",
       "3 -0.635 -0.745 -0.5100  -2.04     4  1.29 -0.89  0.66  0.2498  0.7119     1   \n",
       "4 -0.280 -0.182 -0.4277 -11.12    26  6.11 -3.82  2.51  0.2282 -0.5399     0   \n",
       "\n",
       "   f777  f778  loss  \n",
       "0     0     5     0  \n",
       "1     0     5     0  \n",
       "2     0     5     0  \n",
       "3     0     5     0  \n",
       "4     0     5     0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bruto = pd.read_csv(\"data/train_v2.csv\", header=0)\n",
    "dataset_bruto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bruto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105471 entries, 0 to 105470\n",
      "Columns: 771 entries, id to loss\n",
      "dtypes: float64(653), int64(99), object(19)\n",
      "memory usage: 620.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_bruto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando com uma abordagem simples, \n",
    "- Sem exploração dos dados\n",
    "- em qualquer tratamento\n",
    "- Com uma rede neural simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que a variável a ser prevista é um valor entre 0 e 100, podemos transformar 1 coluna de números inteiros em n colunas booleanas, para cada valor, ou seja, trataremos cada valor como uma categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_numeric = dataset_bruto.apply(pd.to_numeric, errors='coerce')\n",
    "dataset_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105471, 769)\n",
      "(105471,)\n"
     ]
    }
   ],
   "source": [
    "dataset_values = dataset_numeric.values \n",
    "\n",
    "features = dataset_values[:,1:770].astype(float)\n",
    "targets = dataset_values[:,770]\n",
    "\n",
    "print(features.shape)\n",
    "print(targets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que a variável a ser prevista é um valor entre 0 e 100, podemos transformar 1 coluna de números inteiros em n colunas booleanas, para cada valor, ou seja, trataremos cada valor como uma categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(targets)\n",
    "\n",
    "encoded_targets = encoder.transform(targets)\n",
    "dummy_targets = np_utils.to_categorical(encoded_targets)\n",
    "dummy_targets.shape\n",
    "\n",
    "dummy_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de rede neural \"naive\". Apenas 1 layer. Como podemos ver como resultado anterior, temos 89 categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7700      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 89)                979       \n",
      "=================================================================\n",
      "Total params: 8,679\n",
      "Trainable params: 8,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 89)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n = Sequential()\n",
    "model_n.add(Dense(10, input_dim=769, activation='relu')) # 769 features de entrada\n",
    "model_n.add(Dense(89, activation='softmax')) # 89 possíveis categorias de saida.\n",
    "model_n.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_n.summary()\n",
    "model_n.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construido os datasets de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84376, 769)\n",
      "(21095, 769)\n",
      "(84376, 89)\n",
      "(21095, 89)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, dummy_targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84376 samples, validate on 21095 samples\n",
      "Epoch 1/4\n",
      "84376/84376 [==============================] - 5s 56us/step - loss: nan - accuracy: 0.9065 - val_loss: nan - val_accuracy: 0.9060\n",
      "Epoch 2/4\n",
      "84376/84376 [==============================] - 4s 43us/step - loss: nan - accuracy: 0.9076 - val_loss: nan - val_accuracy: 0.9060\n",
      "Epoch 3/4\n",
      "84376/84376 [==============================] - 4s 43us/step - loss: nan - accuracy: 0.9076 - val_loss: nan - val_accuracy: 0.9060\n",
      "Epoch 4/4\n",
      "84376/84376 [==============================] - 4s 43us/step - loss: nan - accuracy: 0.9076 - val_loss: nan - val_accuracy: 0.9060\n"
     ]
    }
   ],
   "source": [
    "history = model_n.fit(X_train, y_train,\n",
    "                    batch_size=500,\n",
    "                    epochs=4,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: nan\n",
      "Test accuracy: 0.9059966802597046\n"
     ]
    }
   ],
   "source": [
    "score = model_n.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0]) # dúvida, por que loss = nan?\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão, sem grandes esforços obtivemos uma acuraciadade de 90,5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novo modelo\n",
    "Neste novo modelo, temos 3 camadas, com maior numero de neuronios cada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_bruto.apply(pd.to_numeric, errors='coerce')\n",
    "dataset = dataset.values\n",
    "X = dataset[:,1:770].astype(float)\n",
    "Y = dataset[:,770]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao invés de manualmete dividirmos as amostrar, podemos utilizar-nos estimators e kfolders, e executarmos o treinamento mais de uma vez.\n",
    "Esta abordagem, realizamos o treino 3 vezes, cada 1 com 10 épocas e batch_size de 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105471, 769)\n",
      "(105471, 89)\n",
      "[[126.          10.           0.6868419  ...   1.           0.\n",
      "    5.        ]\n",
      " [121.          10.           0.78277593 ...   1.           0.\n",
      "    5.        ]\n",
      " [126.          10.           0.50007998 ...   1.           0.\n",
      "    5.        ]\n",
      " ...\n",
      " [129.           9.           0.24185807 ...   1.           0.\n",
      "   93.        ]\n",
      " [129.           9.           0.56971859 ...   1.           0.\n",
      "   93.        ]\n",
      " [129.           9.           0.40770742 ...   1.           0.\n",
      "   93.        ]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "Baseline: nan% (nan%)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(dummy_targets.shape)\n",
    "estimator = KerasClassifier(build_fn = model, epochs=50, batch_size=50, verbose=1)\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(estimator, features, dummy_targets, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the column data types and non-missing values\n",
    "dataset_origin.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_origin.apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise exploratória do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = dataset.values\n",
    "features = val[:,1:770] # a primeira coluna \"id\" foi ignorada, assim como a ultima coluna, que contém o valor a ser previsto.\n",
    "loss = val[:,770]  # última coluna \"loss\" com os valores previstos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise exploratória dos valores de \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.describe(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores de loss estão entre 0 e 100 e são número inteiros.\n",
    "O aproach foi transformar esta coluna \"loss\" em 100 variáveis \"one hot encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o valores a ser previsto \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(loss)\n",
    "encoded_loss = encoder.transform(loss)\n",
    "# conveter mumeros inteiros para categorias≈\n",
    "dummy_loss = np_utils.to_categorical(encoded_loss)\n",
    "dummy_loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado acima mostra que no dataset só existem 89 valores possíveis para loss, assim temos 89 previsões possíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo inicial, para referência,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(10, input_dim=769, activation='relu')) # 769 features de entrada\n",
    "model1.add(Dense(89, activation='softmax')) # 89 possíveis categorias de saida.\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "model1.output_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisão do dataset entre treino do modelo e teste do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, dummy_loss, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(X_train, y_train,\n",
    "                    batch_size=500,\n",
    "                    epochs=3,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0]) # dúvida, por que loss = nan?\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo enfoque.\n",
    "Neste enfoque, utilizaremos uma rede densa com 3 camadas, com 100 neuronios cada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(100, input_dim=769, activation='relu')) # 769 features de entrada\n",
    "model2.add(Dense(89, activation='softmax')) # 89 possíveis categorias de saida.\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()\n",
    "model2.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao invés de dividir a amnostra em duas, iremos utilizar o enfoque kfold, gerando n_splits randomicamente a cada cross_validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(loss)\n",
    "# encoded_Y = encoder.transform(Y)\n",
    "# # convert integers to dummy variables (i.e. one hot encoded)\n",
    "# dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=769, activation='relu'))\n",
    "model.add(Dense(100, input_dim=769, activation='relu'))\n",
    "model.add(Dense(89, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.shape\n",
    "\n",
    "# estimator = KerasClassifier(build_fn=baseline_model, epochs=10, batch_size=500, verbose=1)\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "# results = cross_val_score(estimator, features, dummy_y, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efeitos de comparação, podemos utilizar uma regressão logísitica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regression = dataset_origin.dropna(axis=1)\n",
    "data_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_regression = data_regresion.values\n",
    "features = values_regression[:,1:245] # a primeira coluna \"id\" foi ignorada, assim como a ultima coluna, que contém o valor a ser previsto.\n",
    "loss = values_regression[245]  # última coluna \"loss\" com os valores previstos.\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(loss)\n",
    "# encoded_loss = encoder.transform(loss)\n",
    "\n",
    "# dummy_loss = np_utils.to_categorical(encoded_loss)\n",
    "# dummy_loss.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, z, Y,  y = train_test_split(features, loss, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
